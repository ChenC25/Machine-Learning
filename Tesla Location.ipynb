{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf777b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not fetch the Tesla U.S. Stores page (received repeated 403/blocked responses). Try again later or switch to a headless browser renderer (Selenium/Playwright).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 232\u001b[39m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_XLSX\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 220\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m     df = \u001b[43mscrape_tesla_us_stores\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     df.to_csv(OUTPUT_CSV, index=\u001b[38;5;28;01mFalse\u001b[39;00m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# Excel: ensure engine is available (openpyxl)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 203\u001b[39m, in \u001b[36mscrape_tesla_us_stores\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    201\u001b[39m html = fetch_first_successful_html(session, US_STORES_URLS)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m html:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    204\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not fetch the Tesla U.S. Stores page (received repeated 403/blocked responses). \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    205\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTry again later or switch to a headless browser renderer (Selenium/Playwright).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m     )\n\u001b[32m    208\u001b[39m rows = parse_store_list(html)\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rows:\n",
      "\u001b[31mRuntimeError\u001b[39m: Could not fetch the Tesla U.S. Stores page (received repeated 403/blocked responses). Try again later or switch to a headless browser renderer (Selenium/Playwright)."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Initialize list to store all locations\n",
    "locations = []\n",
    "\n",
    "# Find all state sections\n",
    "state_sections = soup.find_all('div', class_='subregions_page_locations_container')[0].find_all('div', recursive=False)\n",
    "\n",
    "for section in state_sections:\n",
    "    # Check if this section has a state header\n",
    "    state_header = section.find('h4', class_='subregion_header')\n",
    "    if not state_header:\n",
    "        continue\n",
    "        \n",
    "    state = state_header.text.strip()\n",
    "    \n",
    "    # Find all locations in this state\n",
    "    location_containers = section.find_all('div', class_='subregion_location')\n",
    "    \n",
    "    for container in location_containers:\n",
    "        # Extract location name\n",
    "        title_elem = container.find('div', class_='subregion_location_title')\n",
    "        location_name = title_elem.find('p').text.strip() if title_elem and title_elem.find('p') else \"N/A\"\n",
    "        \n",
    "        # Extract address lines\n",
    "        address_lines = []\n",
    "        address_elems = container.find_all('div', class_='subregion_location_addressLine1')\n",
    "        for elem in address_elems:\n",
    "            if 'subregion_location_title' not in elem.get('class', []):  # Avoid double-counting title\n",
    "                address_lines.append(elem.text.strip())\n",
    "        full_address = \", \".join(address_lines)\n",
    "        \n",
    "        # Extract phone number\n",
    "        phone_elem = container.find('a', href=re.compile(r'tel:'))\n",
    "        phone = phone_elem.text.strip() if phone_elem else \"N/A\"\n",
    "        \n",
    "        # Extract coordinates from demo drive link\n",
    "        demo_link = container.find('a', href=re.compile(r'/drive\\?'))\n",
    "        lat, lng = \"N/A\", \"N/A\"\n",
    "        if demo_link and 'href' in demo_link.attrs:\n",
    "            href = demo_link['href']\n",
    "            lat_match = re.search(r'lat=([-0-9.]+)', href)\n",
    "            lng_match = re.search(r'lng=([-0-9.]+)', href)\n",
    "            lat = lat_match.group(1) if lat_match else \"N/A\"\n",
    "            lng = lng_match.group(1) if lng_match else \"N/A\"\n",
    "        \n",
    "        # Add to locations list\n",
    "        locations.append({\n",
    "            'State': state,\n",
    "            'Location Name': location_name,\n",
    "            'Full Address': full_address,\n",
    "            'Phone Number': phone,\n",
    "            'Latitude': lat,\n",
    "            'Longitude': lng\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(locations)\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel('tesla_locations.xlsx', index=False)\n",
    "\n",
    "print(f\"Extracted {len(locations)} locations. Saved to tesla_locations.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
