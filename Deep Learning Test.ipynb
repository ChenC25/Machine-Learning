{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e70e93",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 1. Define feature engineering function\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Define feature engineering function\n",
    "def feature_engineering(df):\n",
    "    # Ensure model_year is integer\n",
    "    df['model_year'] = df['model_year'].fillna(df['model_year'].median()).astype(int)\n",
    "    # Vehicle age\n",
    "    df['vehicle_age'] = 2025 - df['model_year']\n",
    "    df['vehicle_age'] = df['vehicle_age'].replace(0, 0.5)\n",
    "    # Flags and codes\n",
    "    df['drivable_flag'] = (df['drivable'] == 'Y').astype(int)\n",
    "    df['make_code'] = df['make'].astype('category').cat.codes\n",
    "    # Interaction features\n",
    "    df['mileage_age'] = df['mileage'] * df['vehicle_age']\n",
    "    df['grade_drivable'] = df['grade'] * df['drivable_flag']\n",
    "    # Buckets\n",
    "    df['mileage_bucket'] = pd.cut(df['mileage'], bins=[0,50000,100000,150000,200000,300000], labels=False)\n",
    "    df['age_bucket'] = pd.cut(df['vehicle_age'], bins=[0,3,5,8,12,20], labels=False)\n",
    "    # Average price by make\n",
    "    avg_price_make = df.groupby('make')['gross_sale_price'].mean()\n",
    "    df['make_avg_price'] = df['make'].map(avg_price_make)\n",
    "    return df\n",
    "\n",
    "# 2. Load datasets\n",
    "cars = pd.read_csv('Customer Database.csv', encoding='latin1')\n",
    "cars_test = pd.read_excel('OH VINs w. Zips.xlsx')\n",
    "\n",
    "# Add Location to test set\n",
    "cars_test['Location'] = 'OHIO'\n",
    "\n",
    "# Drop unused columns (ignore errors if columns missing)\n",
    "cars = cars.drop(columns=['color','sale_date'], errors='ignore')\n",
    "cars_test = cars_test.drop(columns=['VIN','Auction lights - Green','Auction lights - Red','Zip','Transport Operable','Transport Inop','Representation','Sold Date'], errors='ignore')\n",
    "\n",
    "# Rename columns in test set\n",
    "cars_test = cars_test.rename(columns={\n",
    "    'Year':'model_year',\n",
    "    'Make':'make',\n",
    "    'Model':'model',\n",
    "    'Mileage':'mileage',\n",
    "    'Vehicle Grade (Approved CR)':'grade',\n",
    "    'Operable':'drivable'\n",
    "})\n",
    "\n",
    "# Clean grade and drivable in test\n",
    "cars_test['grade'] = (cars_test['grade']\n",
    "                        .str.replace('Grade','',regex=False)\n",
    "                        .str.replace(': Salvage','',regex=False)\n",
    "                        .str.replace('Unknown','',regex=False)\n",
    "                        .replace('', np.nan))\n",
    "cars_test['grade'] = pd.to_numeric(cars_test['grade'], errors='coerce')\n",
    "cars_test['drivable'] = cars_test['drivable'].replace('Yes','Y')\n",
    "\n",
    "# Apply feature engineering\n",
    "cars = feature_engineering(cars)\n",
    "cars_test = feature_engineering(cars_test)\n",
    "\n",
    "# 3. Define features and target\n",
    "numeric_feats = ['mileage','model_year','grade','vehicle_age','drivable_flag','make_code','mileage_age','grade_drivable','mileage_bucket','age_bucket','make_avg_price']\n",
    "categorical_feats = ['make','model','Location','drivable']\n",
    "target = 'gross_sale_price'\n",
    "\n",
    "# Prepare training data\n",
    "data = cars[numeric_feats + categorical_feats + [target]].dropna()\n",
    "X = data[numeric_feats + categorical_feats]\n",
    "y = data[target]\n",
    "\n",
    "# Split into train/validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Create tf.data datasets\n",
    "batch_size = 32\n",
    "\n",
    "def df_to_dataset(features, labels=None, shuffle=True, batch_size=32):\n",
    "    if labels is not None:\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(buffer_size=len(features))\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_tensor_slices(dict(features))\n",
    "    return ds.batch(batch_size)\n",
    "\n",
    "train_ds = df_to_dataset(X_train, y_train, shuffle=True, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(X_val, y_val, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# 5. Build feature inputs for TF model\n",
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Numeric feature inputs + normalization\n",
    "for feat in numeric_feats:\n",
    "    inp = tf.keras.Input(shape=(1,), name=feat)\n",
    "    norm = tf.keras.layers.Normalization(name=f'norm_{feat}')\n",
    "    norm.adapt(X_train[[feat]])\n",
    "    x = norm(inp)\n",
    "    all_inputs.append(inp)\n",
    "    encoded_features.append(x)\n",
    "\n",
    "# Categorical feature inputs + one-hot\n",
    "for feat in categorical_feats:\n",
    "    inp = tf.keras.Input(shape=(1,), name=feat, dtype='string')\n",
    "    lookup = tf.keras.layers.StringLookup(output_mode='one_hot', name=f'lookup_{feat}')\n",
    "    lookup.adapt(X_train[feat])\n",
    "    x = lookup(inp)\n",
    "    all_inputs.append(inp)\n",
    "    encoded_features.append(x)\n",
    "\n",
    "# Concatenate all features\n",
    "x = tf.keras.layers.concatenate(encoded_features)\n",
    "\n",
    "# 6. Define the neural network\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "output = tf.keras.layers.Dense(1, name='price')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=all_inputs, outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "# 7. Train the model\n",
    "epochs = 50\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)\n",
    "\n",
    "# 8. Evaluate\n",
    "eval_loss, eval_rmse = model.evaluate(val_ds)\n",
    "print(f\"Validation RMSE: {eval_rmse:.2f}\")\n",
    "\n",
    "# 9. Predict on external test set\n",
    "X_test = cars_test[numeric_feats + categorical_feats]\n",
    "test_ds = df_to_dataset(X_test, labels=None, shuffle=False, batch_size=batch_size)\n",
    "preds = model.predict(test_ds).flatten()\n",
    "\n",
    "# 10. Save predictions\n",
    "results = cars_test.copy()\n",
    "results['DL_Predictions'] = preds\n",
    "results.to_excel('DL_Price_Predictions.xlsx', index=False)\n",
    "print('Saved predictions to DL_Price_Predictions.xlsx')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
